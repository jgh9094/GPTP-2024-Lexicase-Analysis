# clean start
rm(list = ls())
cat("\014")
setwd('~/Desktop/Repositories/GPTP-2024-Lexicase-Analysis/')

# libraries we are using
library(dplyr)

# important vars
NAMES = c(50,100,500,1000,5000)
data_dir <- 'Paper_Data/Exploitation/'


# get best performance data 
best <- read.csv(paste(data_dir, 'best.csv', sep = "", collapse = NULL), header = TRUE, stringsAsFactors = FALSE)
best$pop_size <- factor(best$pop_size, levels = NAMES)

best %>%
  group_by(pop_size) %>%
  dplyr::summarise(
    count = n(),
    na_cnt = sum(is.na(performance)),
    min = min(performance, na.rm = TRUE),
    median = median(performance, na.rm = TRUE),
    mean = mean(performance, na.rm = TRUE),
    max = max(performance, na.rm = TRUE),
    IQR = IQR(performance, na.rm = TRUE)
  )

# Kruscal-Wallis test
# p-value < 2.2e-16
kruskal.test(performance ~ pop_size, data = best)

# Pairwise wlcoxon test
pairwise.wilcox.test(x = best$performance, g = best$pop_size, p.adjust.method = "bonferroni",
                     paired = FALSE, conf.int = FALSE, alternative = 'l')


# satisfactory solution found data
ssf <- read.csv(paste(data_dir, 'ssf.csv', sep = "", collapse = NULL), header = TRUE, stringsAsFactors = FALSE)
ssf$pop_size <- factor(ssf$pop_size, levels = NAMES)

ssf %>%
  group_by(pop_size) %>%
  dplyr::summarise(
    count = n(),
    na_cnt = sum(is.na(evaluation)),
    min = min(evaluation, na.rm = TRUE),
    median = median(evaluation, na.rm = TRUE),
    mean = mean(evaluation, na.rm = TRUE),
    max = max(evaluation, na.rm = TRUE),
    IQR = IQR(evaluation, na.rm = TRUE)
  )

# remove failed reps
ssf = filter(ssf, evaluation <= 1500000000)

# Kruscal-Wallis test
# p-value < 2.2e-16
kruskal.test(evaluation ~ pop_size, data = ssf)

# Pairwise wlcoxon test
pairwise.wilcox.test(x = ssf$evaluation, g = ssf$pop_size, p.adjust.method = "bonferroni",
                     paired = FALSE, conf.int = FALSE, alternative = 'g')
